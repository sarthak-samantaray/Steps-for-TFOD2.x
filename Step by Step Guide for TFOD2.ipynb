{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3829b9",
   "metadata": {},
   "source": [
    "STEPS FOR TFOD2.x is same some changes, refer this link:\n",
    "https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d0921",
   "metadata": {},
   "source": [
    "# <center>CREATING ENVIRONMENT</center>\n",
    "\n",
    "```\n",
    "create the env :\n",
    "conda create -n tensorflow pip python=3.9\n",
    "\n",
    "Activate the env : \n",
    "conda activate tfod2\n",
    "\n",
    "Install necessary libraries\n",
    "pip install pillow lxml Cython contextlib2 jupyter matplotlib pandas opencv-python\n",
    "pip install --ignore-installed --upgrade tensorflow==2.5.0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d8be9f",
   "metadata": {},
   "source": [
    "# <center>CHANGIN THE ENVIRONMENT</center>\n",
    "\n",
    "```\n",
    "pip install ipykernel\n",
    "activate your env\n",
    "python -m ipykernel install --user --name=myenv\n",
    "\n",
    "Open Jupyter Notebook and navigate to the notebook for which you want to change the environment.\n",
    "Click on the \"Kernel\" menu on the top of the notebook.\n",
    "In the \"Kernel\" menu, select \"Change Kernel\" and choose the kernel with the name of the environment you just created (in this case, \"myenv\").\n",
    "You should now be able to use the environment you just activated in Jupyter Notebook.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211266f",
   "metadata": {},
   "source": [
    "# <center>IMPORTANT LINKS TO DOWNLOAD FOR TFOD2.x</center>\n",
    "\n",
    "```\n",
    "Download the whole repo, if you are setting up your TFOD1 first time.:\n",
    "step 1 : Downloading the models tree\n",
    "https://github.com/tensorflow/models\n",
    "\n",
    "step 2 : Downloading a pre trained model\n",
    "\n",
    "\n",
    "step 3: model-> model research->type this :\n",
    "for /f %i in ('dir /b object_detection\\protos\\*.proto') do protoc object_detection\\protos\\%i --python_out=.\n",
    "\n",
    "step 4: coco api\n",
    "pip install cython\n",
    "pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\n",
    "\n",
    "step 5: go to reasearch --> object_detection --> packages --> tf2 copy setup.py  and pasete it in research folder.\n",
    "python -m pip install  .\n",
    "\n",
    "\n",
    "Test your Installation:\n",
    "go to reasearch --> object_detection --> packages --> tf2 copy setup.py  and pasete it in research folder.\n",
    "python object_detection/builders/model_builder_tf2_test.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fe70b8",
   "metadata": {},
   "source": [
    "# <center>INSTALL LABELIMG</center>\n",
    "\n",
    "```\n",
    "LINK : https://github.com/heartexlabs/labelImg\n",
    "\n",
    "Windows + Anaconda\n",
    "Download and install Anaconda (Python 3+)\n",
    "\n",
    "Open the Anaconda Prompt and go to the labelImg directory\n",
    "\n",
    "\n",
    "conda install pyqt=5\n",
    "conda install -c anaconda lxml\n",
    "pyrcc5 -o libs/resources.py resources.qrc\n",
    "\n",
    "to run labelimg, run this below code:\n",
    "python labelImg.py\n",
    "\n",
    "python labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64ddaf",
   "metadata": {},
   "source": [
    "# <center> XML to CSV to TF Records </center>\n",
    "```\n",
    "Copy the images from utils in research folder.(VERY IMPORTANT.)\n",
    "\n",
    "\n",
    "xml --> csv --> TF records\n",
    "\n",
    "TF Records is a python file format used by TF community which smaller in size faster, but binary form(special characters).\n",
    "\n",
    "xml to csv, use the script named as xml_to_csv.py\n",
    "\n",
    "csv to TF records.\n",
    "\n",
    "Because we always pass TF records in Training.\n",
    "\n",
    "If you hava JSON, convert that into TF RECORDS.\n",
    "\n",
    "\n",
    "we will follow \n",
    "xml --> csv --> TFRecords --> Binary.\n",
    "\n",
    "\n",
    "How to do it?\n",
    "\n",
    "## copy the file xml_to_csv from utils folder in TFOD1.x folder to TFOD2.x --> workspace-->  training_demo\n",
    "write this command in anaconda(open anaconda in training_demo folder)\n",
    "python xml_to_csv.py\n",
    "\n",
    "it will show converted successfully.\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "For confirmation.\n",
    "You will see test_labels.csv and train_labels.csv in that copied images folder in research folder.\n",
    "\n",
    "Note : If your dataset is very large like 100gb then you divide the data into parts and pass it into tf records.\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Now generate TF RECORDS.\n",
    "\n",
    "## Copy the file tfgenerate.record from utils in TFOD1.x folder to training_demo folder.\n",
    "\n",
    "Write this command-->\n",
    "python generate_tfrecord.py -x images/train -l annotations/label_map.pbtxt -o annotations/train.record\n",
    "\n",
    "python generate_tfrecord.py -x images/test -l annotations/label_map.pbtxt -o annotations/test.record\n",
    "\n",
    "Then check the research folder, it will have test.record and train.record\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7133c690",
   "metadata": {},
   "source": [
    "# <center> IMPORTANT STEPS BEFORE TRAINING THE MODEL. </center>\n",
    "```\n",
    "Create a folder named example:my_faster_rcnn.\n",
    "Copy the pipeline.config from pretrained_models in models-->my_faster_rcnn\n",
    "--------------------------------------------------------------------------------------------\n",
    "some changes in the config file.\n",
    "\n",
    "1. Change the num_classes to 6, because in my cards dataset there are only 6 classes, you can the pbtext file in training folder which is in research folder.\n",
    "\n",
    "2. line 107 : pass the folder path of the pretrained model.\n",
    "\n",
    "3. line 113 change to a smaller number.\n",
    "\n",
    "4. 122 : path of train.record\n",
    "\n",
    "5. 124 : path of labelmap.pbtxt\n",
    "\n",
    "6. 136 : path of test.record\n",
    "\n",
    "7. 138 : path of labelmap.pbtxt\n",
    "\n",
    "8. useb_float = False\n",
    "\n",
    "9. fine_tune_checkpoint_type: \"detection\"\n",
    "\n",
    "_______________________________________________________________________________________________\n",
    "\n",
    "Now go to models-->research-->object_detection copy model_main_tf2.py and paste it in training_demo\n",
    "\n",
    "\n",
    "_________________________________________________________________________________________\n",
    "## Run from training_demo folder.\n",
    "python model_main_tf2.py --model_dir=models/my_ssd_resnet50 --pipeline_config_path=models/my_ssd_resnet50/pipeline.config\n",
    "\n",
    "\n",
    "it will throw an error no modeule net found.\n",
    "\n",
    "go to slim folder in research , \n",
    "copy deployment and nets folder in slim folder in research folder.\n",
    "_______________________________________________________________________________________\n",
    "You can stop your training at any step, and once you again run the above command it will start from the last checkpoint.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca25663",
   "metadata": {},
   "source": [
    "# <center> HOW TO TRAIN??? </center>\n",
    "```\n",
    "##                                   Coverting checkpoints that is ckpt into models(pb format)\n",
    "\n",
    "\n",
    "## research-->object_detection-->export_inference_graph , copy this and paste it in research.\n",
    "\n",
    "## Write this command in research folder.\n",
    "\n",
    "python export_inference_graph.py --input_type image_tensor --pipeline_config_path training\\faster_rcnn_inceptio_v2_coco.config --trained_checkpoint_prefix training\\model.ckpt-2500 --output_directory inference_graph\n",
    "\n",
    "The inference_grpah folder will your main model.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37999ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0f32ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3667c2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31365a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
